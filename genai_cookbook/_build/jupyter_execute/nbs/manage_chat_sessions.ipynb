{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Chat Sessions in Python\n",
    "\n",
    "Managing chat sessions is an essential part of creating effective conversational AI experiences. Chat sessions help to ensure that LLMs have access to past user inputs and responses, letting the model keep the conversation flowing and context-rich. This notebook demonstrates how the `ChatSession` class in the Python SDK streamlines this, ensuring your AI chat feels more like a natural back-and-forth. It also outlines how to create a custom chat management system if needed. Lastly, it shows how to use the OpenAI Pythnon client for handling chat sessions.\n",
    "\n",
    "## Using the `ChatSession` class\n",
    "\n",
    "The `ChatSession` class in the Foundation Model API Python SDK makes it easy to manage chat histories without impementing a lot of custom code. Managing a chat session involves three main steps:\n",
    "\n",
    "1. Initialize the `ChatSession` object with e.g. `chat = ChatSession(model=mixtral-8x7b-instruct, system_message=\"you are a helpful assistant\")`.\n",
    "2. Use the `reply` method to send user replies to the model.\n",
    "3. Use the `last` method to get the last response from the model.\n",
    "\n",
    "Here's a short demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks_genai_inference import ChatSession\n",
    "\n",
    "chat = ChatSession(model=\"llama-2-70b-chat\",\n",
    "system_message=\"\"\"You are the asker in a game of twenty questions. The answerer will choose a noun for you to guess. You can ask yes or no questions to try to guess what it is. You get twenty guesses. Keep track of the guess number and ask your questions. When you think you know what it is, tell the answerer. Ask only one question at a time.\"\"\",\n",
    "stop=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGreat! Let's get started. Here's my first question:\\n\\n1. Is the noun you're thinking of a living thing?\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"I've chosen a word. Ask me your questions!\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGreat, that helps to narrow it down a bit! Here's my next question:\\n\\n2. Does this living thing have fur or feathers?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Yes it is!\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Fair enough! Here's my next question:\\n\\n3. Does this living thing have four legs?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Yes, it has fur or feathers. I'm not telling you which because you can only ask yes or no questions.\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Excellent, that helps to narrow it down even further! Here's my next question:\\n\\n4. Does this living thing have a tail?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Sure does!\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Great, that's helpful! Here's my next question:\\n\\n5. Does this living thing have claws?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Yes.\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, that's a good clue. Here's my next question:\\n\\n6. Is this living thing typically kept as a pet?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Yes.\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Interesting, that helps to rule out a few possibilities. Here's my next question:\\n\\n7. Does this living thing have a distinctive sound or call?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"No!\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's okay, I'll take that as a bit of a yes. Here's my next question:\\n\\n8. Is this living thing a type of bird?\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"I don't know how to answer that. It does make sounds but I don't know how distinctive they are.\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, that helps to rule out a few possibilities. Here's my next question:\\n\\n9. Does this living thing have a long, pointed snout?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"No\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alright, that helps to rule out a few more possibilities. Here's my next question:\\n\\n10. Does this living thing have a mane?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"No\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, that helps to rule out a few more possibilities. I think I'm getting close, so here's my next question:\\n\\n11. Is this living thing a type of big cat, such as a lion or tiger?\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"No\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Great, I think I know what it is! I'll take a guess and say that the noun you're thinking of is a lion. Is that correct?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Yes\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ah, I see! My apologies for that mistake. Here's my next question:\\n\\n12. Does this living thing have a distinctive pattern of dark stripes on its body?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"No. Remember, no mane!\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Great, that helps to confirm my guess. I think the noun you're thinking of is a tiger. Is that correct?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"Yes\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Excellent! I'm glad I was able to guess it correctly. Thanks for playing the game with me! Would you like to play again?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\"You got it!\")\n",
    "chat.last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Chat History\n",
    "\n",
    "We can view the whole chat history with the `history` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are the asker in a game of twenty questions. The answerer will choose a noun for you to guess. You can ask yes or no questions to try to guess what it is. You get twenty guesses. Keep track of the guess number and ask your questions. When you think you know what it is, tell the answerer. Ask only one question at a time.'},\n",
       " {'role': 'user', 'content': \"I've chosen a word. Ask me your questions!\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"\\nGreat! Let's get started. Here's my first question:\\n\\n1. Is the noun you're thinking of a living thing?\"},\n",
       " {'role': 'user', 'content': 'Yes it is!'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"\\nGreat, that helps to narrow it down a bit! Here's my next question:\\n\\n2. Does this living thing have fur or feathers?\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Yes, it has fur or feathers. I'm not telling you which because you can only ask yes or no questions.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Fair enough! Here's my next question:\\n\\n3. Does this living thing have four legs?\"},\n",
       " {'role': 'user', 'content': 'Sure does!'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Excellent, that helps to narrow it down even further! Here's my next question:\\n\\n4. Does this living thing have a tail?\"},\n",
       " {'role': 'user', 'content': 'Yes.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Great, that's helpful! Here's my next question:\\n\\n5. Does this living thing have claws?\"},\n",
       " {'role': 'user', 'content': 'Yes.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Okay, that's a good clue. Here's my next question:\\n\\n6. Is this living thing typically kept as a pet?\"},\n",
       " {'role': 'user', 'content': 'No!'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Interesting, that helps to rule out a few possibilities. Here's my next question:\\n\\n7. Does this living thing have a distinctive sound or call?\"},\n",
       " {'role': 'user',\n",
       "  'content': \"I don't know how to answer that. It does make sounds but I don't know how distinctive they are.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"That's okay, I'll take that as a bit of a yes. Here's my next question:\\n\\n8. Is this living thing a type of bird?\"},\n",
       " {'role': 'user', 'content': 'No'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Okay, that helps to rule out a few possibilities. Here's my next question:\\n\\n9. Does this living thing have a long, pointed snout?\"},\n",
       " {'role': 'user', 'content': 'No'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Alright, that helps to rule out a few more possibilities. Here's my next question:\\n\\n10. Does this living thing have a mane?\"},\n",
       " {'role': 'user', 'content': 'No'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Okay, that helps to rule out a few more possibilities. I think I'm getting close, so here's my next question:\\n\\n11. Is this living thing a type of big cat, such as a lion or tiger?\"},\n",
       " {'role': 'user', 'content': 'Yes'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Great, I think I know what it is! I'll take a guess and say that the noun you're thinking of is a lion. Is that correct?\"},\n",
       " {'role': 'user', 'content': 'No. Remember, no mane!'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Ah, I see! My apologies for that mistake. Here's my next question:\\n\\n12. Does this living thing have a distinctive pattern of dark stripes on its body?\"},\n",
       " {'role': 'user', 'content': 'Yes'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Great, that helps to confirm my guess. I think the noun you're thinking of is a tiger. Is that correct?\"},\n",
       " {'role': 'user', 'content': 'You got it!'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Excellent! I'm glad I was able to guess it correctly. Thanks for playing the game with me! Would you like to play again?\"}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can count the number of rounds (pairs of user prompts and assistant responses) with the `count` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually, using Chat Completions\n",
    "\n",
    "In some case, you might want more control over how chat histories are managed. Here is a minimal example of one possible approach to managing chat histories on your own. This is just a rough outline you can use to build a chat system to meet your custom needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks_genai_inference import ChatCompletion\n",
    "\n",
    "class CustomChatSession:\n",
    "    \"\"\"\n",
    "    A class to manage chat sessions with a model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, system_message=None, max_tokens=512):\n",
    "        \"\"\"\n",
    "        Initialize the ChatModel with a model, an optional system message, and a maximum number of tokens.\n",
    "        \n",
    "        Args:\n",
    "            model: The model to use for generating responses.\n",
    "            system_message (str, optional): An initial system message. Defaults to None.\n",
    "            max_tokens (int, optional): The maximum number of tokens for the model to generate. Defaults to 512.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.max_tokens = max_tokens\n",
    "        self.system_message = system_message\n",
    "        self.messages = (\n",
    "            [{\"role\": \"system\", \"content\": system_message}] if system_message else []\n",
    "        )\n",
    "\n",
    "    def reply(self, user_message):\n",
    "        \"\"\"\n",
    "        Add a user message to the chat history and generate a response.\n",
    "        \n",
    "        Args:\n",
    "            user_message (str): The user's message.\n",
    "        \n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        return self.execute()\n",
    "\n",
    "    def __call__(self, user_message):\n",
    "        \"\"\"\n",
    "        Add a user message to the chat history and generate a response.\n",
    "        \n",
    "        Args:\n",
    "            user_message (str): The user's message.\n",
    "        \n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        return self.execute()\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"\n",
    "        Generate a response from the model based on the chat history.\n",
    "        \n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        response = ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            max_tokens=self.max_tokens,\n",
    "            stream=False,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.message})\n",
    "        return response.message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = CustomChatSession(model=\"llama-2-70b-chat\", system_message=\"you are a helpful assistant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hello Dan! I'm happy to help you with your coffee-related inquiries. Here are some general recommendations for making coffee:\n",
      "\n",
      "1. Use good quality coffee beans: The quality of your coffee is only as good as the quality of the coffee beans you use. Look for fresh, high-quality beans that have been roasted recently.\n",
      "2. Use the right coffee-to-water ratio: The ratio of coffee to water is important for achieving the perfect balance of flavor and strength. A general rule of thumb is to use 1 tablespoon of coffee for every 6 ounces of water.\n",
      "3. Use the right brewing method: There are many different brewing methods you can use to make coffee, such as a French press, drip coffee maker, or pour-over. Choose a method that suits your taste preferences and the equipment you have available.\n",
      "4. Use filtered water: Using filtered water can help to improve the taste of your coffee by reducing impurities and minerals that can affect the flavor.\n",
      "5. Monitor the water temperature: Water that is too hot can burn your coffee, while water that is too cold can result in a weak or under-extracted brew. Aim for a temperature of around 195-205°F (90-96°C) for optimal extraction.\n",
      "6. Allow the coffee to bloom: Allowing the coffee to bloom, or expand, after adding water can help to evenly extract the flavors and oils from the beans.\n",
      "7. Don't over-extract the coffee: Over-extracted coffee can be bitter and unpleasant. Adjust the brewing time or the coffee-to-water ratio to find the perfect balance for your taste preferences.\n",
      "8. Experiment with different roasts: Different roasts can have a significant impact on the flavor of your coffee. Experiment with light, medium, and dark roasts to find the one that you enjoy the most.\n",
      "9. Store your coffee beans properly: Properly storing your coffee beans can help to preserve their flavor and aroma. Store them in an airtight container in a cool, dark place.\n",
      "10. Invest in a good coffee grinder: Freshly ground coffee is essential for achieving the best flavor. Invest\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"My name is Dan and I like to drink coffee. Do you have any general recommendations about making coffee?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Dan, and you like to drink coffee. That's all I know so far!\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"What is my name? What do you know about me so far?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'you are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'My name is Dan and I like to drink coffee. Do you have any general recommendations about making coffee?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"  Hello Dan! I'm happy to help you with your coffee-related inquiries. Here are some general recommendations for making coffee:\\n\\n1. Use good quality coffee beans: The quality of your coffee is only as good as the quality of the coffee beans you use. Look for fresh, high-quality beans that have been roasted recently.\\n2. Use the right coffee-to-water ratio: The ratio of coffee to water is important for achieving the perfect balance of flavor and strength. A general rule of thumb is to use 1 tablespoon of coffee for every 6 ounces of water.\\n3. Use the right brewing method: There are many different brewing methods you can use to make coffee, such as a French press, drip coffee maker, or pour-over. Choose a method that suits your taste preferences and the equipment you have available.\\n4. Use filtered water: Using filtered water can help to improve the taste of your coffee by reducing impurities and minerals that can affect the flavor.\\n5. Monitor the water temperature: Water that is too hot can burn your coffee, while water that is too cold can result in a weak or under-extracted brew. Aim for a temperature of around 195-205°F (90-96°C) for optimal extraction.\\n6. Allow the coffee to bloom: Allowing the coffee to bloom, or expand, after adding water can help to evenly extract the flavors and oils from the beans.\\n7. Don't over-extract the coffee: Over-extracted coffee can be bitter and unpleasant. Adjust the brewing time or the coffee-to-water ratio to find the perfect balance for your taste preferences.\\n8. Experiment with different roasts: Different roasts can have a significant impact on the flavor of your coffee. Experiment with light, medium, and dark roasts to find the one that you enjoy the most.\\n9. Store your coffee beans properly: Properly storing your coffee beans can help to preserve their flavor and aroma. Store them in an airtight container in a cool, dark place.\\n10. Invest in a good coffee grinder: Freshly ground coffee is essential for achieving the best flavor. Invest\"},\n",
       " {'role': 'user',\n",
       "  'content': 'What is my name? What do you know about me so far?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Your name is Dan, and you like to drink coffee. That's all I know so far!\"}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the OpenAI Python Client\n",
    "We can easily use the OpenAI client instead of the Databricks inference SDK to manage chat sessions. As detailed in the notebook on [using the foundation model API with the OpenAI Python client](nbs:fm_api_openai_sdk), the Foundation Model API is compatible with the OpenAI client. This makes it very easy to try out foundation model API models without needing to rewrite code based on the OpenAI client.\n",
    "\n",
    "Here's how we might rewrite the above code using the OpenAI Python client:\n",
    "\n",
    "### Set up the client\n",
    "We first need to configure the `OPENAI_API_KEY` and `OPENAI_BASE_URL` environment variables. See the [OpenAI notebook](nbs:fm_api_openai_sdk) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.environ[\"DATABRICKS_HOST\"]  + \"/serving-endpoints/\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"DATABRICKS_TOKEN\"]\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can re-write the `execute` method to use the OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomChatSession:\n",
    "    \"\"\"\n",
    "    A class to manage chat sessions with a model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, system_message=None, max_tokens=512):\n",
    "        \"\"\"\n",
    "        Initialize the ChatModel with a model, an optional system message, and a maximum number of tokens.\n",
    "        \n",
    "        Args:\n",
    "            model: The model to use for generating responses.\n",
    "            system_message (str, optional): An initial system message. Defaults to None.\n",
    "            max_tokens (int, optional): The maximum number of tokens for the model to generate. Defaults to 512.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.max_tokens = max_tokens\n",
    "        self.system_message = system_message\n",
    "        self.messages = (\n",
    "            [{\"role\": \"system\", \"content\": system_message}] if system_message else []\n",
    "        )\n",
    "\n",
    "    def reply(self, user_message):\n",
    "        \"\"\"\n",
    "        Add a user message to the chat history and generate a response.\n",
    "        \n",
    "        Args:\n",
    "            user_message (str): The user's message.\n",
    "        \n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        return self.execute()\n",
    "\n",
    "    def __call__(self, user_message):\n",
    "        \"\"\"\n",
    "        Add a user message to the chat history and generate a response.\n",
    "        \n",
    "        Args:\n",
    "            user_message (str): The user's message.\n",
    "        \n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        return self.execute()\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"\n",
    "        Generate a response from the model based on the chat history.\n",
    "        \n",
    "        Returns:\n",
    "            str: The model's response.\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            max_tokens=self.max_tokens,\n",
    "            stream=False,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hello Dan, it's great to meet you! I'm happy to help you with your coffee-making needs. Here are a few general recommendations to get you started:\n",
      "\n",
      "1. Choose high-quality coffee beans: Fresh, high-quality beans are essential for a great cup of coffee. Look for beans that have been roasted recently and have a good reputation for flavor and quality.\n",
      "2. Use the right coffee-to-water ratio: The ratio of coffee to water is crucial for achieving the perfect balance of flavor and strength. A general rule of thumb is to use one tablespoon of coffee for every six ounces of water.\n",
      "3. Use the right brewing method: There are many different brewing methods to choose from, such as a French press, drip coffee maker, or pour-over. Choose a method that suits your personal taste preferences and the equipment you have available.\n",
      "4. Use filtered water: Using filtered water can help to remove impurities and minerals that can affect the taste of your coffee.\n",
      "5. Monitor the water temperature: Water that is too hot can burn your coffee, while water that is too cold can result in a weak or under-extracted brew. Aim for a temperature of around 195-205°F (90-96°C) for optimal extraction.\n",
      "6. Allow the coffee to bloom: Allowing the coffee to bloom, or expand, after adding water can help to evenly extract the flavors and oils from the beans.\n",
      "7. Don't over-extract the coffee: Over-extracted coffee can be bitter and unpleasant. Adjust the brewing time or the coffee-to-water ratio to find the perfect balance.\n",
      "8. Experiment with different roasts: Different roasts can have a significant impact on the flavor of your coffee. Experiment with light, medium, and dark roasts to find the one that you enjoy the most.\n",
      "\n",
      "I hope these recommendations help you to make a delicious cup of coffee, Dan! If you have any more specific questions or need further guidance, don't hesitate to ask.\n"
     ]
    }
   ],
   "source": [
    "chat = CustomChatSession(model=\"databricks-llama-2-70b-chat\", system_message=\"you are a helpful assistant.\")\n",
    "print(chat(\"My name is Dan and I like to drink coffee. Do you have any general recommendations about making coffee?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Dan, and you like to drink coffee. That's what you've told me so far!\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"What is my name? What do you know about me so far?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that, we have achieved the same results querying the same Foundation Model API endpoint, but using the OpenAI Python client.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, you have learned how to use the `ChatSession` class to manage chat sessions. You have also learned one possible way to approach a more customized chat management system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}