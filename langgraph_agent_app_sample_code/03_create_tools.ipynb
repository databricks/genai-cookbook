{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31661828-f9bb-4fc2-a1bd-94424a27ed52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ‘‰ START HERE: How to use this notebook\n",
    "\n",
    "# Step 2: Create tools for your Agent\n",
    "\n",
    "<todo>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d9f685a-fdb7-49a4-9e3a-a4a9e964d045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Important note:** Throughout this notebook, we indicate which cell's code you:\n",
    "- âœ…âœï¸ should customize - these cells contain code & config with business logic that you should edit to meet your requirements & tune quality.\n",
    "- ðŸš«âœï¸ should not customize - these cells contain boilerplate code required to load/save/execute your Agent\n",
    "\n",
    "*Cells that don't require customization still need to be run!  You CAN change these cells, but if this is the first time using this notebook, we suggest not doing so.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb4f8cc0-1797-4beb-a9f2-df21a9db79f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸš«âœï¸ Install Python libraries\n",
    "\n",
    "You do not need to modify this cell unless you need additional Python packages in your Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d4030e8-ae97-4351-bebd-9651d283578f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qqqq -U -r requirements.txt\n",
    "# Restart to load the packages into the Python environment\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fa580a1-524b-4058-830d-7d3a72169fde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸš«âœï¸ Connect to Databricks\n",
    "\n",
    "If running locally in an IDE using Databricks Connect, connect the Spark client & configure MLflow to use Databricks Managed MLflow.  If this running in a Databricks Notebook, these values are already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a08da9d7-152a-44c8-9609-2ffebcc1ad25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if not du.is_in_databricks_notebook():\n",
    "    from databricks.connect import DatabricksSession\n",
    "    import os\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6be96e1a-d2fa-4acd-b54e-d7fe85d0034d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ðŸš«âœï¸ Load the Agent's UC storage locations; set up MLflow experiment\n",
    "\n",
    "This notebook uses the UC model, MLflow Experiment, and Evaluation Set that you specified in the [Agent setup](02_agent_setup.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413ef673-1912-4600-bde2-1beaaa4f9919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import mlflow \n",
    "from box import Box\n",
    "from cookbook.databricks_utils import get_table_url\n",
    "from cookbook.databricks_utils import get_mlflow_experiment_url\n",
    "\n",
    "# Load the Agent's storage configuration\n",
    "agent_storage_config = Box(yaml.safe_load(Path(\"./configs/agent_storage_config.yaml\").read_text()))\n",
    "print(agent_storage_config)\n",
    "\n",
    "\n",
    "# set the MLflow experiment\n",
    "experiment_info = mlflow.set_experiment(agent_storage_config.mlflow_experiment_name)\n",
    "# If running in a local IDE, set the MLflow experiment name as an environment variable\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = agent_storage_config.mlflow_experiment_name\n",
    "\n",
    "print(f\"View the MLflow Experiment `{agent_storage_config.mlflow_experiment_name}` at {get_mlflow_experiment_url(experiment_info.experiment_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3bfc354-785f-4e0a-8245-fe05389769d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# create tools\n",
    "\n",
    "- we will store all tools in the `user_tools` folder\n",
    "- first, create a local function & test it with pytest\n",
    "- then, deploy it as a UC tool & test it with pytest\n",
    "- then, add the tool to the Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c054346-e4f6-42a7-9403-9882f2450b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "always reload the tool's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "320ca179-916a-4ec7-b012-dd9915adbbc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b0d70d2-17b1-4fdf-a5f9-da75332c4a5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## lets do an example of a simple, but fake tool that translates old to new SKUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54ae1351-99f9-4e42-85a1-e56b7882509b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1, create the python function that will become your UC function.  you need to annotate the function with docstrings & type hints - these are used to create the tool's metadata in UC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1375dbe-003c-4aee-bb1d-f5922c716242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile tools/sample_tool.py\n",
    "\n",
    "def sku_sample_translator(old_sku: str) -> str:\n",
    "    \"\"\"\n",
    "    Translates a pre-2024 SKU formatted as \"OLD-XXX-YYYY\" to the new SKU format \"NEW-YYYY-XXX\".\n",
    "\n",
    "    Args:\n",
    "        old_sku (str): The old SKU in the format \"OLD-XXX-YYYY\".\n",
    "\n",
    "    Returns:\n",
    "        str: The new SKU in the format \"NEW-YYYY-XXX\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the SKU format is invalid, providing specific error details.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    if not isinstance(old_sku, str):\n",
    "        raise ValueError(\"SKU must be a string\")\n",
    "\n",
    "    # Normalize input by removing extra whitespace and converting to uppercase\n",
    "    old_sku = old_sku.strip().upper()\n",
    "\n",
    "    # Define the regex pattern for the old SKU format\n",
    "    pattern = r\"^OLD-([A-Z]{3})-(\\d{4})$\"\n",
    "\n",
    "    # Match the old SKU against the pattern\n",
    "    match = re.match(pattern, old_sku)\n",
    "    if not match:\n",
    "        if not old_sku.startswith(\"OLD-\"):\n",
    "            raise ValueError(\"SKU must start with 'OLD-'\")\n",
    "        if not re.match(r\"^OLD-[A-Z]{3}-\\d{4}$\", old_sku):\n",
    "            raise ValueError(\n",
    "                \"SKU format must be 'OLD-XXX-YYYY' where X is a letter and Y is a digit\"\n",
    "            )\n",
    "        raise ValueError(\"Invalid SKU format\")\n",
    "\n",
    "    # Extract the letter code and numeric part\n",
    "    letter_code, numeric_part = match.groups()\n",
    "\n",
    "    # Additional validation for numeric part\n",
    "    if not (1 <= int(numeric_part) <= 9999):\n",
    "        raise ValueError(\"Numeric part must be between 0001 and 9999\")\n",
    "\n",
    "    # Construct the new SKU\n",
    "    new_sku = f\"NEW-{numeric_part}-{letter_code}\"\n",
    "    return new_sku\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa0474ad-8ee2-4148-9018-aa78b37ded7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, let's import the tool and test it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "034892a0-c83c-4c95-b318-83d369f9a153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tools.sample_tool import sku_sample_translator\n",
    "\n",
    "sku_sample_translator(\"OLD-XXX-1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e7b9a25-c7e6-48ac-9d3e-86ec325d524c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "now, lets write some pyTest unit tests for the tool - these are just samples, you will need to write your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ac4fd62-270c-443a-8b17-1b6bb8e00f58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile tools/test_sample_tool.py\n",
    "import pytest\n",
    "from tools.sample_tool import sku_sample_translator\n",
    "\n",
    "\n",
    "\n",
    "def test_valid_sku_translation():\n",
    "    \"\"\"Test successful SKU translation with valid input.\"\"\"\n",
    "    assert sku_sample_translator(\"OLD-ABC-1234\") == \"NEW-1234-ABC\"\n",
    "    assert sku_sample_translator(\"OLD-XYZ-0001\") == \"NEW-0001-XYZ\"\n",
    "    assert sku_sample_translator(\"old-def-5678\") == \"NEW-5678-DEF\"  # Test case insensitivity\n",
    "\n",
    "\n",
    "def test_whitespace_handling():\n",
    "    \"\"\"Test that the function handles extra whitespace correctly.\"\"\"\n",
    "    assert sku_sample_translator(\"  OLD-ABC-1234  \") == \"NEW-1234-ABC\"\n",
    "    assert sku_sample_translator(\"\\tOLD-ABC-1234\\n\") == \"NEW-1234-ABC\"\n",
    "\n",
    "\n",
    "def test_invalid_input_type():\n",
    "    \"\"\"Test that non-string inputs raise ValueError.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"SKU must be a string\"):\n",
    "        sku_sample_translator(123)\n",
    "    with pytest.raises(ValueError, match=\"SKU must be a string\"):\n",
    "        sku_sample_translator(None)\n",
    "\n",
    "\n",
    "def test_invalid_prefix():\n",
    "    \"\"\"Test that SKUs not starting with 'OLD-' raise ValueError.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"SKU must start with 'OLD-'\"):\n",
    "        sku_sample_translator(\"NEW-ABC-1234\")\n",
    "    with pytest.raises(ValueError, match=\"SKU must start with 'OLD-'\"):\n",
    "        sku_sample_translator(\"XXX-ABC-1234\")\n",
    "\n",
    "\n",
    "def test_invalid_format():\n",
    "    \"\"\"Test various invalid SKU formats.\"\"\"\n",
    "    invalid_skus = [\n",
    "        \"OLD-AB-1234\",  # Too few letters\n",
    "        \"OLD-ABCD-1234\",  # Too many letters\n",
    "        \"OLD-123-1234\",  # Numbers instead of letters\n",
    "        \"OLD-ABC-123\",  # Too few digits\n",
    "        \"OLD-ABC-12345\",  # Too many digits\n",
    "        \"OLD-ABC-XXXX\",  # Letters instead of numbers\n",
    "        \"OLD-A1C-1234\",  # Mixed letters and numbers in middle\n",
    "    ]\n",
    "\n",
    "    for sku in invalid_skus:\n",
    "        with pytest.raises(\n",
    "            ValueError,\n",
    "            match=\"SKU format must be 'OLD-XXX-YYYY' where X is a letter and Y is a digit\",\n",
    "        ):\n",
    "            sku_sample_translator(sku)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b6add46-090e-4160-afdf-1e7a9a5ff46c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "now, lets run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da7b4dba-a9cc-4f0b-9fdd-606afd01d6b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if du.is_in_databricks_notebook():\n",
    "    import sys\n",
    "    sys.dont_write_bytecode = True # Skip writing .pyc files to the bytecode cache on the cluster.\n",
    "\n",
    "# Run tests from test_sku_translator.py\n",
    "pytest.main([\"-v\", \"tools/test_sample_tool.py\", \"-o cache_dir=/tmp/my_cache_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dbdb1e7-85e6-45c8-8f39-46f982dd1464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, lets deploy the tool to Unity catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85196db9-c0f8-4e86-8ad0-94653a1850f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "from tools.sample_tool import sku_sample_translator\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "CATALOG = \"shared\"  # Change me!\n",
    "SCHEMA = \"cookbook_langgraph_udhay\"  # Change me if you want\n",
    "\n",
    "# this will deploy the tool to UC, automatically setting the metadata in UC based on the tool's docstring & typing hints\n",
    "tool_uc_info = client.create_python_function(func=sku_sample_translator, catalog=CATALOG, schema=SCHEMA, replace=True)\n",
    "\n",
    "# the tool will deploy to a function in UC called `{catalog}.{schema}.{func}` where {func} is the name of the function\n",
    "# Print the deployed Unity Catalog function name\n",
    "print(f\"Deployed Unity Catalog function name: {tool_uc_info.full_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a9bac0a-ac9b-4857-913f-3ca9d4a0e8ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, wrap it into a UCTool that will be used by our Agent.  UC tool is just a Pydnatic base model that is serializable to YAML that will load the tool's metadata from UC and wrap it in a callable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f9f657c-dea4-412e-b5e3-a6fb8ca3354e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "# wrap the tool into a UCTool which can be passed to our Agent\n",
    "translate_sku_tool = UCTool(uc_function_name=tool_uc_info.full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84efc805-cc4d-4a8d-afca-ff9b37d794eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, let's test the UC tool - the UCTool is a directly callable wrapper around the UC function, so it can be used just like a local function, but the output will be put into a dictionary with either the output in a 'value' key or an 'error' key if an error is raised.\n",
    "\n",
    "when an error happens, the UC tool will also return an instruction prompt to show the agent how to think about handling the error.  this can be changed via the `error_prompt` parameter in the UCTool..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "276fd791-ff41-4440-bb89-895e5778b64f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# successful call\n",
    "translate_sku_tool(old_sku=\"OLD-XXX-1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1e1a4ce-2f4b-4222-a1fb-c9b2f7f95d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# unsuccessful call\n",
    "translate_sku_tool(old_sku=\"OxxLD-XXX-1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b44f626-6dc9-4117-a85a-79120569f4d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "now, let's convert our pytests to work with the UC tool.  this requires a bit of transformation to the test code to account for the fact that the output is in a dictionary & exceptions are not raised directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74e2f618-ecb7-44f1-bdbd-a3badac81e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile tools/test_sample_tool_uc.py\n",
    "import pytest\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "CATALOG = \"shared\"  # Change me!\n",
    "SCHEMA = \"cookbook_langgraph_udhay\"  # Change me if you want\n",
    "\n",
    "# Load the function from the UCTool versus locally\n",
    "@pytest.fixture\n",
    "def uc_tool():\n",
    "    \"\"\"Fixture to translate a UC tool into a local function.\"\"\"\n",
    "    UC_FUNCTION_NAME = f\"{CATALOG}.{SCHEMA}.sku_sample_translator\"\n",
    "    loaded_tool = UCTool(uc_function_name=UC_FUNCTION_NAME)\n",
    "    return loaded_tool\n",
    "\n",
    "\n",
    "# Note: The value will be post processed into the `value` key, so we must check the returned value there.\n",
    "def test_valid_sku_translation(uc_tool):\n",
    "    \"\"\"Test successful SKU translation with valid input.\"\"\"\n",
    "    assert uc_tool(old_sku=\"OLD-ABC-1234\")[\"value\"] == \"NEW-1234-ABC\"\n",
    "    assert uc_tool(old_sku=\"OLD-XYZ-0001\")[\"value\"] == \"NEW-0001-XYZ\"\n",
    "    assert (\n",
    "        uc_tool(old_sku=\"old-def-5678\")[\"value\"] == \"NEW-5678-DEF\"\n",
    "    )  # Test case insensitivity\n",
    "\n",
    "\n",
    "# Note: The value will be post processed into the `value` key, so we must check the returned value there.\n",
    "def test_whitespace_handling(uc_tool):\n",
    "    \"\"\"Test that the function handles extra whitespace correctly.\"\"\"\n",
    "    assert uc_tool(old_sku=\"  OLD-ABC-1234  \")[\"value\"] == \"NEW-1234-ABC\"\n",
    "    assert uc_tool(old_sku=\"\\tOLD-ABC-1234\\n\")[\"value\"] == \"NEW-1234-ABC\"\n",
    "\n",
    "\n",
    "# Note: the input validation happens BEFORE the function is called by Spark, so we will never get these exceptions from the function.\n",
    "# Instead, we will get invalid parameters errors from Spark.\n",
    "def test_invalid_input_type(uc_tool):\n",
    "    \"\"\"Test that non-string inputs raise ValueError.\"\"\"\n",
    "    assert (\n",
    "        uc_tool(old_sku=123)[\"error\"][\"error_message\"]\n",
    "        == \"\"\"Invalid parameters provided: {'old_sku': \"Parameter old_sku should be of type STRING (corresponding python type <class 'str'>), but got <class 'int'>\"}.\"\"\"\n",
    "    )\n",
    "    assert (\n",
    "        uc_tool(old_sku=None)[\"error\"][\"error_message\"]\n",
    "        == \"\"\"Invalid parameters provided: {'old_sku': \"Parameter old_sku should be of type STRING (corresponding python type <class 'str'>), but got <class 'NoneType'>\"}.\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Note: The errors will be post processed into the `error_message` key inside the `error` top level key, so we must check for exceptions there.\n",
    "def test_invalid_prefix(uc_tool):\n",
    "    \"\"\"Test that SKUs not starting with 'OLD-' raise ValueError.\"\"\"\n",
    "    assert (\n",
    "        uc_tool(old_sku=\"NEW-ABC-1234\")[\"error\"][\"error_message\"]\n",
    "        == \"ValueError: SKU must start with 'OLD-'\"\n",
    "    )\n",
    "    assert (\n",
    "        uc_tool(old_sku=\"XXX-ABC-1234\")[\"error\"][\"error_message\"]\n",
    "        == \"ValueError: SKU must start with 'OLD-'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Note: The errors will be post processed into the `error_message` key inside the `error` top level key, so we must check for exceptions there.\n",
    "def test_invalid_format(uc_tool):\n",
    "    \"\"\"Test various invalid SKU formats.\"\"\"\n",
    "    invalid_skus = [\n",
    "        \"OLD-AB-1234\",  # Too few letters\n",
    "        \"OLD-ABCD-1234\",  # Too many letters\n",
    "        \"OLD-123-1234\",  # Numbers instead of letters\n",
    "        \"OLD-ABC-123\",  # Too few digits\n",
    "        \"OLD-ABC-12345\",  # Too many digits\n",
    "        \"OLD-ABC-XXXX\",  # Letters instead of numbers\n",
    "        \"OLD-A1C-1234\",  # Mixed letters and numbers in middle\n",
    "    ]\n",
    "\n",
    "    expected_error = \"ValueError: SKU format must be 'OLD-XXX-YYYY' where X is a letter and Y is a digit\"\n",
    "    for sku in invalid_skus:\n",
    "        assert uc_tool(old_sku=sku)[\"error\"][\"error_message\"] == expected_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec50dbed-a6e0-4d6d-8bdd-8d6736aec694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if du.is_in_databricks_notebook():\n",
    "    import sys\n",
    "    sys.dont_write_bytecode = True # Skip writing .pyc files to the bytecode cache on the cluster.\n",
    "\n",
    "# Run tests from test_sku_translator.py\n",
    "pytest.main([\"-v\", \"tools/test_sample_tool_uc.py\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a17e7b0-53b6-434f-8e17-f4d3678f7c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Now, here's another example of a tool that executes python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc16221b-7ad6-4cd5-84c9-702319b7c260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile tools/code_exec.py\n",
    "def python_exec(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Executes Python code in the sandboxed environment and returns its stdout. The runtime is stateless and you can not read output of the previous tool executions. i.e. No such variables \"rows\", \"observation\" defined. Calling another tool inside a Python code is NOT allowed.\n",
    "    Use only standard python libraries and these python libraries: bleach, chardet, charset-normalizer, defusedxml, googleapis-common-protos, grpcio, grpcio-status, jmespath, joblib, numpy, packaging, pandas, patsy, protobuf, pyarrow, pyparsing, python-dateutil, pytz, scikit-learn, scipy, setuptools, six, threadpoolctl, webencodings, user-agents, cryptography.\n",
    "\n",
    "    Args:\n",
    "      code (str): Python code to execute. Remember to print the final result to stdout.\n",
    "\n",
    "    Returns:\n",
    "      str: The output of the executed code.\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "\n",
    "    sys_stdout = sys.stdout\n",
    "    redirected_output = StringIO()\n",
    "    sys.stdout = redirected_output\n",
    "    exec(code)\n",
    "    sys.stdout = sys_stdout\n",
    "    return redirected_output.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b583963-bb02-4b1d-947d-63ddc704b416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tools.code_exec import python_exec\n",
    "\n",
    "python_exec(\"print('hello')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43205daf-63a5-405e-86ee-26767c9291c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9394e8f-218c-40c2-84af-085a87fdca28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile tools/test_code_exec.py\n",
    "\n",
    "import pytest\n",
    "from .code_exec import python_exec\n",
    "\n",
    "\n",
    "def test_basic_arithmetic():\n",
    "    code = \"\"\"result = 2 + 2\\nprint(result)\"\"\"\n",
    "    assert python_exec(code).strip() == \"4\"\n",
    "\n",
    "\n",
    "def test_multiple_lines():\n",
    "    code = \"x = 5\\n\" \"y = 3\\n\" \"result = x * y\\n\" \"print(result)\"\n",
    "    assert python_exec(code).strip() == \"15\"\n",
    "\n",
    "\n",
    "def test_multiple_prints():\n",
    "    code = \"\"\"print('first')\\nprint('second')\\nprint('third')\\n\"\"\"\n",
    "    expected = \"first\\nsecond\\nthird\\n\"\n",
    "    assert python_exec(code) == expected\n",
    "\n",
    "\n",
    "def test_using_pandas():\n",
    "    code = (\n",
    "        \"import pandas as pd\\n\"\n",
    "        \"data = {'col1': [1, 2], 'col2': [3, 4]}\\n\"\n",
    "        \"df = pd.DataFrame(data)\\n\"\n",
    "        \"print(df.shape)\"\n",
    "    )\n",
    "    assert python_exec(code).strip() == \"(2, 2)\"\n",
    "\n",
    "\n",
    "def test_using_numpy():\n",
    "    code = \"import numpy as np\\n\" \"arr = np.array([1, 2, 3])\\n\" \"print(arr.mean())\"\n",
    "    assert python_exec(code).strip() == \"2.0\"\n",
    "\n",
    "\n",
    "def test_syntax_error():\n",
    "    code = \"if True\\n\" \"    print('invalid syntax')\"\n",
    "    with pytest.raises(SyntaxError):\n",
    "        python_exec(code)\n",
    "\n",
    "\n",
    "def test_runtime_error():\n",
    "    code = \"x = 1 / 0\\n\" \"print(x)\"\n",
    "    with pytest.raises(ZeroDivisionError):\n",
    "        python_exec(code)\n",
    "\n",
    "\n",
    "def test_undefined_variable():\n",
    "    code = \"print(undefined_variable)\"\n",
    "    with pytest.raises(NameError):\n",
    "        python_exec(code)\n",
    "\n",
    "\n",
    "def test_multiline_string_manipulation():\n",
    "    code = \"text = '''\\n\" \"Hello\\n\" \"World\\n\" \"'''\\n\" \"print(text.strip())\"\n",
    "    expected = \"Hello\\nWorld\"\n",
    "    assert python_exec(code).strip() == expected\n",
    "\n",
    "# Will not fail locally, but will fail in UC.\n",
    "# def test_unauthorized_flask():\n",
    "#     code = \"from flask import Flask\\n\" \"app = Flask(__name__)\\n\" \"print(app)\"\n",
    "#     with pytest.raises(ImportError):\n",
    "#         python_exec(code)\n",
    "\n",
    "\n",
    "def test_no_print_statement():\n",
    "    code = \"x = 42\\n\" \"y = x * 2\"\n",
    "    assert python_exec(code) == \"\"\n",
    "\n",
    "\n",
    "def test_calculation_without_print():\n",
    "    code = \"result = sum([1, 2, 3, 4, 5])\\n\" \"squared = [x**2 for x in range(5)]\"\n",
    "    assert python_exec(code) == \"\"\n",
    "\n",
    "\n",
    "def test_function_definition_without_call():\n",
    "    code = \"def add(a, b):\\n\" \"    return a + b\\n\" \"result = add(3, 4)\"\n",
    "    assert python_exec(code) == \"\"\n",
    "\n",
    "\n",
    "def test_class_definition_without_instantiation():\n",
    "    code = (\n",
    "        \"class Calculator:\\n\"\n",
    "        \"    def add(self, a, b):\\n\"\n",
    "        \"        return a + b\\n\"\n",
    "        \"calc = Calculator()\"\n",
    "    )\n",
    "    assert python_exec(code) == \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "681450a6-84a6-4a76-b734-403e569de7b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from mlflow.utils import databricks_utils as du\n",
    "\n",
    "if du.is_in_databricks_notebook():\n",
    "    import sys\n",
    "    sys.dont_write_bytecode = True # Skip writing .pyc files to the bytecode cache on the cluster.\n",
    "\n",
    "# Run tests from test_code_exec.py\n",
    "pytest.main([\"-v\", \"tools/test_code_exec.py\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10a2bece-4e96-4201-b3f8-42054875f10f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Deploy to UC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27f1ab60-0d37-447f-adf1-40ba52794398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "from tools.code_exec import python_exec\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "CATALOG = \"shared\"  # Change me!\n",
    "SCHEMA = \"cookbook_langgraph_udhay\"  # Change me if you want\n",
    "\n",
    "# this will deploy the tool to UC, automatically setting the metadata in UC based on the tool's docstring & typing hints\n",
    "python_exec_tool_uc_info = client.create_python_function(func=python_exec, catalog=CATALOG, schema=SCHEMA, replace=True)\n",
    "\n",
    "# the tool will deploy to a function in UC called `{catalog}.{schema}.{func}` where {func} is the name of the function\n",
    "# Print the deployed Unity Catalog function name\n",
    "print(f\"Deployed Unity Catalog function name: {python_exec_tool_uc_info.full_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db12518d-8c11-4bc8-8d47-9996d54adc9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test as UC Tool for the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb292ee7-b2ff-43d2-9fa1-fb84767970bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "\n",
    "# wrap the tool into a UCTool which can be passed to our Agent\n",
    "python_exec_tool = UCTool(uc_function_name=python_exec_tool_uc_info.full_name)\n",
    "\n",
    "python_exec_tool(code=\"print('hello')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9210666e-1849-4885-aa1a-8e0b912f57f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "New tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85df2d06-6978-48ba-b9de-143f02374206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile tools/test_code_exec_as_uc_tool.py\n",
    "\n",
    "import pytest\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "\n",
    "CATALOG = \"shared\"  # Change me!\n",
    "SCHEMA = \"cookbook_langgraph_udhay\"  # Change me if you want\n",
    "\n",
    "\n",
    "@pytest.fixture\n",
    "def python_exec():\n",
    "    \"\"\"Fixture to provide the python_exec function from UCTool.\"\"\"\n",
    "    python_exec_tool = UCTool(uc_function_name=f\"{CATALOG}.{SCHEMA}.python_exec\")\n",
    "    return python_exec_tool\n",
    "\n",
    "\n",
    "def test_basic_arithmetic(python_exec):\n",
    "    code = \"\"\"result = 2 + 2\\nprint(result)\"\"\"\n",
    "    assert python_exec(code=code)[\"value\"].strip() == \"4\"\n",
    "\n",
    "\n",
    "def test_multiple_lines(python_exec):\n",
    "    code = \"x = 5\\n\" \"y = 3\\n\" \"result = x * y\\n\" \"print(result)\"\n",
    "    assert python_exec(code=code)[\"value\"].strip() == \"15\"\n",
    "\n",
    "\n",
    "def test_multiple_prints(python_exec):\n",
    "    code = \"\"\"print('first')\\nprint('second')\\nprint('third')\\n\"\"\"\n",
    "    expected = \"first\\nsecond\\nthird\\n\"\n",
    "    assert python_exec(code=code)[\"value\"] == expected\n",
    "\n",
    "\n",
    "def test_using_pandas(python_exec):\n",
    "    code = (\n",
    "        \"import pandas as pd\\n\"\n",
    "        \"data = {'col1': [1, 2], 'col2': [3, 4]}\\n\"\n",
    "        \"df = pd.DataFrame(data)\\n\"\n",
    "        \"print(df.shape)\"\n",
    "    )\n",
    "    assert python_exec(code=code)[\"value\"].strip() == \"(2, 2)\"\n",
    "\n",
    "\n",
    "def test_using_numpy(python_exec):\n",
    "    code = \"import numpy as np\\n\" \"arr = np.array([1, 2, 3])\\n\" \"print(arr.mean())\"\n",
    "    assert python_exec(code=code)[\"value\"].strip() == \"2.0\"\n",
    "\n",
    "\n",
    "def test_syntax_error(python_exec):\n",
    "    code = \"if True\\n\" \"    print('invalid syntax')\"\n",
    "    result = python_exec(code=code)\n",
    "    assert \"Syntax error at or near 'invalid'.\" in result[\"error\"][\"error_message\"]\n",
    "\n",
    "\n",
    "def test_runtime_error(python_exec):\n",
    "    code = \"x = 1 / 0\\n\" \"print(x)\"\n",
    "    result = python_exec(code=code)\n",
    "    assert \"ZeroDivisionError\" in result[\"error\"][\"error_message\"]\n",
    "\n",
    "\n",
    "def test_undefined_variable(python_exec):\n",
    "    code = \"print(undefined_variable)\"\n",
    "    result = python_exec(code=code)\n",
    "    assert \"NameError\" in result[\"error\"][\"error_message\"]\n",
    "\n",
    "\n",
    "def test_multiline_string_manipulation(python_exec):\n",
    "    code = \"text = '''\\n\" \"Hello\\n\" \"World\\n\" \"'''\\n\" \"print(text.strip())\"\n",
    "    expected = \"Hello\\nWorld\"\n",
    "    assert python_exec(code=code)[\"value\"].strip() == expected\n",
    "\n",
    "\n",
    "def test_unauthorized_flask(python_exec):\n",
    "    code = \"from flask import Flask\\n\" \"app = Flask(__name__)\\n\" \"print(app)\"\n",
    "    result = python_exec(code=code)\n",
    "    assert (\n",
    "        \"ModuleNotFoundError: No module named 'flask'\"\n",
    "        in result[\"error\"][\"error_message\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def test_no_print_statement(python_exec):\n",
    "    code = \"x = 42\\n\" \"y = x * 2\"\n",
    "    assert python_exec(code=code)[\"value\"] == \"\"\n",
    "\n",
    "\n",
    "def test_calculation_without_print(python_exec):\n",
    "    code = \"result = sum([1, 2, 3, 4, 5])\\n\" \"squared = [x**2 for x in range(5)]\"\n",
    "    assert python_exec(code=code)[\"value\"] == \"\"\n",
    "\n",
    "\n",
    "def test_function_definition_without_call(python_exec):\n",
    "    code = \"def add(a, b):\\n\" \"    return a + b\\n\" \"result = add(3, 4)\"\n",
    "    assert python_exec(code=code)[\"value\"] == \"\"\n",
    "\n",
    "\n",
    "def test_class_definition_without_instantiation(python_exec):\n",
    "    code = (\n",
    "        \"class Calculator:\\n\"\n",
    "        \"    def add(self, a, b):\\n\"\n",
    "        \"        return a + b\\n\"\n",
    "        \"calc = Calculator()\"\n",
    "    )\n",
    "    assert python_exec(code=code)[\"value\"] == \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3571724d-9a65-4743-8f73-2c94c2d8334d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "if du.is_in_databricks_notebook():\n",
    "    import sys\n",
    "    sys.dont_write_bytecode = True # Skip writing .pyc files to the bytecode cache on the cluster.\n",
    "\n",
    "# Run tests from test_code_exec_as_uc_tool.py\n",
    "pytest.main([\"-v\", \"tools/test_code_exec_as_uc_tool.py\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_create_tools",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "genai-cookbook-T2SdtsNM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
