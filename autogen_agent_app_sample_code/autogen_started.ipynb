{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f11e094-fffb-4ab5-9a3c-c8e096072b24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qqqq -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e304bc46-67f7-415f-9c39-2fcd173a8af4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e450879c-040b-4168-83e4-e41a4d1e54b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cookbook.tools.vector_search import (\n",
    "    VectorSearchRetrieverTool,\n",
    "    VectorSearchSchema,\n",
    ")\n",
    "from cookbook.tools.uc_tool import UCTool\n",
    "from cookbook.agents.utils.databricks_model_serving_client import DatabricksModelServingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3fca500-aa82-47dc-9154-71a6e1a9f73e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retriever_tool = VectorSearchRetrieverTool(\n",
    "    name=\"search_product_docs\",\n",
    "    description=\"Use this tool to search for product documentation.\",\n",
    "    vector_search_index=\"dbdemos.dbdemos_rag_chatbot.databricks_documentation_vs_index\",\n",
    "    vector_search_schema=VectorSearchSchema(\n",
    "        # These columns are the default values used in the `01_data_pipeline` notebook\n",
    "        # If you used a different column names in that notebook OR you are using a pre-built vector index, update the column names here.\n",
    "        chunk_text=\"content\",  # Contains the text of each document chunk\n",
    "        document_uri=\"url\",  # The document URI of the chunk e.g., \"/Volumes/catalog/schema/volume/file.pdf\" - displayed as the document ID in the Review App\n",
    "        # additional_metadata_columns=[],  # Additional columns to return from the vector database and present to the LLM\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "translate_sku_tool = UCTool(uc_function_name=\"devanshu_pandey.cmhc_demo.vector_index_search_tool\")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c10ef87a-b8e5-45e8-8dcb-8f93f10be258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "entry_point = dbutils.notebook.entry_point\n",
    "\n",
    "host_name = f'https://{entry_point.getDbutils().notebook().getContext().browserHostName().get()}'\n",
    "\n",
    "token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f8ce82-4f8b-483d-ac34-72f0a553a592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_url = f\"{host_name}/serving-endpoints/\"\n",
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c130294-fa62-4c16-8b4a-a22ec87e8b3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_list = {\n",
    "    \"model_client_cls\": \"DatabricksModelServingClient\",\n",
    "    \"model\": \"gpt4o\",\n",
    "    \"endpoint_name\": \"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    \"llm_config\": {\"temperature\": 0.5, \"max_tokens\": 1500}\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ce707e4-97dc-4675-b177-059af76c5408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def is_termination_message(message):\n",
    "    content = message.get(\"content\", \"\")\n",
    "    return (content and \"TERMINATE\" in content.upper()) or (message['role'] == 'user' and 'tool_calls' not in message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950623c1-a8e6-4ee0-b363-dde5cebc509d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "def create_agents(system_prompt, chat_history):\n",
    "    # The user proxy agent is used for interacting with the assistant agent\n",
    "    # and executes tool calls.\n",
    "    user_proxy = ConversableAgent(\n",
    "        name=\"User\",\n",
    "        llm_config=False,\n",
    "        is_termination_msg=is_termination_message,\n",
    "        human_input_mode=\"NEVER\",\n",
    "    )\n",
    "\n",
    "    assistant = ConversableAgent(\n",
    "        name=\"Assistant\",\n",
    "        system_message=\"You are a helpful AI assistant. \"\n",
    "        \"You can help with simple calculations. \"\n",
    "        \"Return 'TERMINATE' when the task is done.\",\n",
    "        llm_config={\"config_list\": [config_list]},\n",
    "        chat_messages={user_proxy: chat_history}\n",
    "    )\n",
    "\n",
    "    return assistant, user_proxy\n",
    "    \n",
    "assistant, user_proxy = create_agents('test', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12b8fb8e-1496-4fa3-8914-e450ba096851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from autogen import register_function\n",
    "\n",
    "for tool in tools:\n",
    "  register_function(\n",
    "      tool,\n",
    "      caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "      executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "      name=tool.name,\n",
    "      description=tool.description,  # A description of the tool.\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ba1c2c1-a7f3-4506-8b79-cec97ee7e92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "translate_sku_tool._toolkit.tools[0].register_function(callers = assistant,\n",
    "                                executors = user_proxy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b4a8bc2-1b7a-4880-952c-4b185fa3b47f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assistant.register_model_client(model_client_cls=DatabricksModelServingClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a90296d7-57ef-4c48-829d-3ab3eca6e2db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant, message=\"What is mlflow in databricks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ff36339-23e9-42f2-964c-ad6eea85ef40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assistant.last_message(user_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92599841-450c-425d-bede-309459a037c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history = assistant.chat_messages[user_proxy]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d128ab-713c-4871-b18a-c5aa42544437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assistant, user_proxy = create_agents('test', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "911a9c70-7291-467c-9a22-1b4bbf9b31b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assistant.chat_messages[user_proxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f99b1e8-3a67-4acc-a765-aafe506c10aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assistant.register_model_client(model_client_cls=DatabricksModelServingClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7393180-cd57-48fc-af71-27f9b04fa205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_result = user_proxy.initiate_chat(assistant, message=\"Can you summary our actual conversation?\", clear_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b2976c3-0360-419d-8667-4a2495706777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assistant.last_message(user_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aed2716-89ef-4d68-be61-14d6c6494eae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from autogen import GroupChat, GroupChatManager\n",
    "from autogen import register_function\n",
    "from cookbook.agents.genie_agent import GenieAgent\n",
    "\n",
    "'''\n",
    "config_list = {\n",
    "    \"model\": \"casaman-gpt4o\",\n",
    "    \"base_url\": base_url,\n",
    "    \"api_key\": token,\n",
    "}\n",
    "'''\n",
    "\n",
    "config_list = {\n",
    "    \"model_client_cls\": \"DatabricksModelServingClient\",\n",
    "    \"model\": \"gpt4o\",\n",
    "    \"endpoint_name\": \"casaman-gpt4o\",\n",
    "    \"llm_config\": {\"temperature\": 0.01, \"max_tokens\": 1500}\n",
    "}\n",
    "\n",
    "genie_agent = GenieAgent(\"Genie\", genie_space_id=\"01ef92421847143785bb9e765454528e\")\n",
    "\n",
    "genie_agent.description = \"You are a Genie Agent. Genie is a helpful AI Assistant that helps to answer questions about a database that contains structured data. It helps to answer questions about the metadata of the tables in the database and also answers questions about the data in the tables.\"\n",
    "\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=is_termination_message,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Function_Tool_Agent\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "        \"You can help with questions related with Databricks documentation.\",\n",
    "    llm_config={\"config_list\": [config_list], \"cache_seed\": None}\n",
    ")\n",
    "\n",
    "assistant.description = \"You are a helful AI assistant. You can help with questions related with Databricks documentation.\"\n",
    "\n",
    "\n",
    "for tool in tools:\n",
    "  register_function(\n",
    "      tool,\n",
    "      caller=assistant,  # The assistant agent can suggest calls to the calculator.\n",
    "      executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "      name=tool.name,\n",
    "      description=tool.description,  # A description of the tool.\n",
    "  )\n",
    "\n",
    "system_message = \"You are in a role play game. The following roles are available: {roles}. Read the following conversation. Then select the next role from {agentlist} to play or return TERMINATE if the task is solved. Only return the role.\"\n",
    "\n",
    "last_message = \"Read the above conversation. Then select the next role from {agentlist} to play or return TERMINATE if the task is solved. Only return the role.\"\n",
    "\n",
    "\n",
    "group_chat = GroupChat([assistant, user_proxy, genie_agent], messages=[], max_round=2, speaker_selection_method=\"auto\",\n",
    "                       select_speaker_message_template=system_message,\n",
    "                       select_speaker_prompt_template=last_message,\n",
    "                       select_speaker_auto_model_client_cls=DatabricksModelServingClient,\n",
    "                       select_speaker_auto_llm_config={\"config_list\": [config_list]} )\n",
    "\n",
    "is_termination_msg = lambda x: \"TERMINATE\" in x.get(\"content\", \"\")\n",
    "\n",
    "group_chat_manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config={\"config_list\": [config_list], \"cache_seed\": None},\n",
    "    is_termination_msg=is_termination_msg\n",
    ")\n",
    "\n",
    "assistant.register_model_client(DatabricksModelServingClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "495ab46e-9ce1-4f1c-a004-8bf6a9bb1892",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_result = user_proxy.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=\"Can you tell me what tables you have access to?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ba80780-33a5-47c7-a574-c464f2c650b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_result = user_proxy.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=\"what is mlflow in databricks?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c07d5ff8-5bda-4a3e-a160-985764e5e311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chat_result = user_proxy.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=\"Do you know something about DLT in databricks?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9898341-5fe5-4509-be47-afb386b3b829",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_chat_manager.last_message(user_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08b89b48-7959-4989-86ad-50d56c9e46d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "group_chat_manager.chat_messages[user_proxy][-2]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "autogen_started",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
