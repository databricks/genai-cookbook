{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0640741-6d84-482a-aa79-f87b04d04023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üëâ START HERE: How to use this notebook\n",
    "\n",
    "### Step 1: Agent storage configuration\n",
    "\n",
    "This notebook initializes a `AgentStorageConfig` Pydantic class to define the locations where the Agent's code/config and its supporting data & metadata is stored in the Unity Catalog:\n",
    "- **Unity Catalog Model:** Stores staging/production versions of the Agent's code/config\n",
    "- **MLflow Experiment:** Stores every development version of the Agent's code/config, each version's associated quality/cost/latency evaluation results, and any MLflow Traces from your development & evaluation processes\n",
    "- **Evaluation Set Delta Table:** Stores the Agent's evaluation set\n",
    "\n",
    "This notebook does the following:\n",
    "1. Validates the provided locations exist.\n",
    "2. Serializes this configuration to `config/agent_storage_config.yaml` so other notebooks can use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7702011a-84dd-4281-bba1-ea9e2b5e551d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Important note:** Throughout this notebook, we indicate which cells you:\n",
    "- ‚úÖ‚úèÔ∏è *should* customize - these cells contain config settings to change\n",
    "- üö´‚úèÔ∏è *typically will not* customize - these cells contain boilerplate code required to validate / save the configuration\n",
    "\n",
    "*Cells that don't require customization still need to be run!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8963d6e-3123-4095-bb92-9d508c52ed41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üö´‚úèÔ∏è Install Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a145c3b-d3d9-4b95-b7f6-22e1d8e991c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.1.20 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.3.24 which is incompatible.\nlangchain 0.1.20 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.2.2 which is incompatible.\nlangchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.3.24 which is incompatible.\nlangchain-community 0.0.38 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.2.2 which is incompatible.\nlangchain-text-splitters 0.0.2 requires langchain-core<0.3,>=0.1.28, but you have langchain-core 0.3.24 which is incompatible.\nydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.2.3 which is incompatible.\nydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.10.3 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -qqqq -U -r requirements.txt\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fff62a18-ac56-497b-82c2-f32bd7d88061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üö´‚úèÔ∏è Connect to Databricks\n",
    "\n",
    "If running locally in an IDE using Databricks Connect, connect the Spark client & configure MLflow to use Databricks Managed MLflow.  If this running in a Databricks Notebook, these values are already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f31cbb-504f-4ca1-b96c-d8ecc37d5f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.utils import databricks_utils as du\n",
    "import os\n",
    "if not du.is_in_databricks_notebook():\n",
    "    from databricks.connect import DatabricksSession\n",
    "\n",
    "    spark = DatabricksSession.builder.getOrCreate()\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9feb28c-c72b-49b2-bbc4-a9bd4721a7cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üö´‚úèÔ∏è Get current user info to set default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7824cc0a-1b29-4cf9-a974-2c5ef885979f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User email: manffred.calvosanchez@databricks.com\nUser name: manffred_calvosanchez\nDefault UC catalog: sunny_uc\n"
     ]
    }
   ],
   "source": [
    "from cookbook.databricks_utils import get_current_user_info\n",
    "\n",
    "user_email, user_name, default_catalog = get_current_user_info(spark)\n",
    "\n",
    "print(f\"User email: {user_email}\")\n",
    "print(f\"User name: {user_name}\")\n",
    "print(f\"Default UC catalog: {default_catalog}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b684188-d4eb-4944-86ae-9942a68308c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ‚úÖ‚úèÔ∏è Configure your Agent's storage locations\n",
    "\n",
    "Either review & accept the default values or enter your preferred location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64682c1f-7e61-430e-84c9-4fb9cad8152b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All catalogs and schemas exist for both model `casaman_ssa.demos.my_agent_autogen` and evaluation table `casaman_ssa.demos.my_agent_autogen_eval_set`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/11 18:01:36 INFO mlflow.tracking.fluent: Experiment with name '/Users/manffred.calvosanchez@databricks.com/my_agent_autogen_mlflow_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the MLflow Experiment `/Users/manffred.calvosanchez@databricks.com/my_agent_autogen_mlflow_experiment` at https://adb-984752964297111.11.azuredatabricks.net/ml/experiments/2822477370659093\n"
     ]
    }
   ],
   "source": [
    "from cookbook.config.shared.agent_storage_location import AgentStorageConfig\n",
    "from cookbook.databricks_utils import get_mlflow_experiment_url\n",
    "import mlflow\n",
    "\n",
    "# Default values below for `AgentStorageConfig` \n",
    "agent_name = \"my_agent_autogen\"\n",
    "uc_catalog_name = \"casaman_ssa\"\n",
    "uc_schema_name = \"demos\"\n",
    "\n",
    "# Agent storage configuration\n",
    "agent_storage_config = AgentStorageConfig(\n",
    "    uc_model_name=f\"{uc_catalog_name}.{uc_schema_name}.{agent_name}\",  # UC model to store staging/production versions of the Agent's code/config\n",
    "    evaluation_set_uc_table=f\"{uc_catalog_name}.{uc_schema_name}.{agent_name}_eval_set\",  # UC table to store the evaluation set\n",
    "    mlflow_experiment_name=f\"/Users/{user_email}/{agent_name}_mlflow_experiment\",  # MLflow Experiment to store development versions of the Agent and their associated quality/cost/latency evaluation results + MLflow Traces\n",
    ")\n",
    "\n",
    "# Validate the UC catalog and schema for the Agent'smodel & evaluation table\n",
    "is_valid, msg = agent_storage_config.validate_catalog_and_schema()\n",
    "if not is_valid:\n",
    "    raise Exception(msg)\n",
    "\n",
    "# Set the MLflow experiment, validating the path is valid\n",
    "experiment_info = mlflow.set_experiment(agent_storage_config.mlflow_experiment_name)\n",
    "# If running in a local IDE, set the MLflow experiment name as an environment variable\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = agent_storage_config.mlflow_experiment_name\n",
    "\n",
    "print(f\"View the MLflow Experiment `{agent_storage_config.mlflow_experiment_name}` at {get_mlflow_experiment_url(experiment_info.experiment_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a49117d-f136-41fa-807d-8be60b863fa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üö´‚úèÔ∏è Save the configuration for use by other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dd99015-5b0d-420b-8a3e-067d84b84dc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from cookbook.config import serializable_config_to_yaml_file\n",
    "\n",
    "serializable_config_to_yaml_file(agent_storage_config, \"./configs/agent_storage_config.yaml\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_agent_setup",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "genai-cookbook-T2SdtsNM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}